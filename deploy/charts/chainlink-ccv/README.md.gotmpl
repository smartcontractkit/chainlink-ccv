{{ template "chart.header" . }}
{{ template "chart.deprecationWarning" . }}

{{ template "chart.badgesSection" . }}

{{ template "chart.description" . }}

{{ template "chart.homepageLine" . }}

{{ template "chart.maintainersSection" . }}

{{ template "chart.sourcesSection" . }}

{{ template "chart.requirementsSection" . }}

## Installation

#### Installation w/o provisioner locally

Installation on local cluster has been tested with [`k3d`](https://github.com/k3d-io/k3d).

If the architecture of your local machine is `amd64`, the public chainlink image can be used. If the architecture is `arm64`, the image needs to be built from source or copied from private sdlc account.

```sh
# set env vars
export AWS_ACCOUNT="<number>"
export AWS_REGION="<region>"
export CHART_VERSION="<version>"

# login to ecr registry
aws ecr get-login-password --region us-west-2 |
  docker login --username AWS --password-stdin $AWS_ACCOUNT.dkr.ecr.us-west-2.amazonaws.com

# pull image
docker pull $AWS_ACCOUNT.dkr.ecr.us-west-2.amazonaws.com/chainlink-develop:develop

# retag image
docker tag 795953128386.dkr.ecr.us-west-2.amazonaws.com/chainlink-develop:develop localhost:5001/chainlink:local

# import image into k3d
k3d image import localhost:5001/chainlink:local --cluster chainlink
```

Once the docker image has been sourced / built:

- create `chainlink` namespace

```sh
kubectl create namespace chainlink
```

- install postgres instance

```sh
helm install pg oci://registry-1.docker.io/bitnamicharts/postgresql -n chainlink -f values.pg.yaml
```

- install chainlink node(s)

```sh
helm template cln-misc-s-n . \
-n chainlink \
-f shared.v2Config-defaults.yaml \
-f shared.v2Config-rpc-ethereum-sepolia.yaml \
-f values.single-node.yaml \
-f shared.deploy-local.yaml \
> debug.single-node.local.yaml
# | kubectl apply -f -
# | kubectl delete -f -
```

#### Installation w/ provisioner on AWS EKS

- `values.single-node.yaml`: deploy single node on testnet (sepolia)

```sh
helm template cln-misc-s-n . \
-n chainlink \
-f shared.v2Config-defaults.yaml \
-f shared.v2Config-rpc-ethereum-sepolia.yaml \
-f values.single-node.yaml \
-f shared.deploy-eks.yaml \
> debug.single-node.yaml
# | kubectl apply -f -
# | kubectl delete -f -
```

- `values.single-boot.yaml`: deploy single boot node on testnet (sepolia)

```sh
helm template cln-misc-s-b . \
-n chainlink \
-f shared.v2Config-defaults.yaml \
-f shared.v2Config-rpc-ethereum-sepolia.yaml \
-f values.single-boot.yaml \
-f shared.deploy-eks.yaml \
> debug.single-boot.yaml
# | kubectl apply -f -
# | kubectl delete -f -
```

- `values.multi-node.yaml`: deploy multiple nodes on testnet (sepolia)

```sh
helm template clc-misc-m-n . \
-n chainlink \
-f shared.v2Config-defaults.yaml \
-f shared.v2Config-rpc-ethereum-sepolia.yaml \
-f values.multi-node.yaml \
-f shared.deploy-eks.yaml \
> debug.multi-node.yaml
# | kubectl apply -f -
# | kubectl delete -f -
```

- `values.multi-boot.yaml`: deploy multiple boot nodes on testnet (sepolia)

```sh
helm template clc-misc-m-b . \
-n chainlink \
-f shared.v2Config-defaults.yaml \
-f shared.v2Config-rpc-ethereum-sepolia.yaml \
-f values.multi-boot.yaml \
-f shared.deploy-eks.yaml \
> debug.multi-boot.yaml
# | kubectl apply -f -
# | kubectl delete -f -
```

- `values.multi-node-single-boot.yaml`: deploy multiple nodes and single boot node on testnet (sepolia)

```sh
helm template clc-misc-m-n-s-b . \
-n chainlink \
-f shared.deploy-eks.yaml \
-f shared.v2Config-defaults.yaml \
-f shared.v2Config-rpc-ethereum-sepolia.yaml \
-f values.multi-node-single-boot.yaml \
> debug.multi-node-single-boot.yaml
# | kubectl apply -f -
# | kubectl delete -f -
```

- `values.multi-node-multi-boot.yaml`: deploy multiple nodes and multiple boot nodes on testnet (sepolia)

```sh
helm template clc-misc-m-n-s-b . \
-n chainlink \
-f shared.v2Config-defaults.yaml \
-f shared.v2Config-rpc-ethereum-sepolia.yaml \
-f values.multi-node-multi-boot.yaml \
-f shared.deploy-eks.yaml \
> debug.multi-node-multi-boot.yaml
# | kubectl apply -f -
# | kubectl delete -f -
```

## Development

### Testing

Unit testing is done using the [helm unittest](https://github.com/helm-unittest/helm-unittest) plugin. To install the plugin run:

```sh
helm plugin install https://github.com/helm-unittest/helm-unittest.git
```

Currently, we have only implemented snapshot testing for each of the different types of configs. To run the test suite, run:

```sh
helm unittest .
```

When developing, we should add a new test case for all new functionality. There should be a test to run it locally and on our AWS EKS clusters. To update the snapshots, run:

```sh
helm unittest -u .
```

Example output testing each config:

```sh
âžœ helm unittest .

### Chart [ chainlink-cluster ] .

 PASS  test multi node local    tests/multi_node_local_test.yaml
 PASS  test multi node multi boot local tests/multi_node_multi_boot_local_test.yaml
 PASS  test multi node multi boot       tests/multi_node_multi_boot_test.yaml
 PASS  test multi node single boot local        tests/multi_node_single_boot_local_test.yaml
 PASS  test multi node single boot      tests/multi_node_single_boot_test.yaml
 PASS  test multi node single boot vpn  tests/multi_node_single_boot_vpn_test.yaml
 PASS  test multi node  tests/multi_node_test.yaml
 PASS  test single boot local   tests/single_boot_local_test.yaml
 PASS  test single boot tests/single_boot_test.yaml
 PASS  test single node ingress tests/single_node_ingress_test.yaml
 PASS  test single node local   tests/single_node_local_test.yaml
 PASS  test single node rollout tests/single_node_rollout_test.yaml
 PASS  test single node tests/single_node_test.yaml
 PASS  test single node vpn     tests/single_node_vpn_test.yaml

Charts:      1 passed, 1 total
Test Suites: 14 passed, 14 total
Tests:       14 passed, 14 total
Snapshot:    256 passed, 256 total
Time:        268.808375ms
```

### Packaging

Below are the steps to package the helm chart and push to an aws oci registry:

```sh
# set env vars
export AWS_ACCOUNT="<number>"
export AWS_REGION="<region>"
export CHART_VERSION="<version>"

# login to ecr registry
aws ecr get-login-password --region "$AWS_REGION" |
  helm registry login --username AWS --password-stdin $AWS_ACCOUNT.dkr.ecr.$AWS_REGION.amazonaws.com/infra-charts

# package charts into tgz
helm package -u -d packages .

# push package to ecr registry
helm push "packages/chainlink-cluster-$CHART_VERSION.tgz" oci://$AWS_ACCOUNT.dkr.ecr.$AWS_REGION.amazonaws.com/infra-charts
```

## Resources

The following resources are created through this helm chart:

- service account: `name=<instance>`
- role: `name=<instance>-role`
- role binding: `name=<instance>-rolebinding`
- network policies (optional): `name=<instance>-netpol`
- per node:
  - deployment / rollout: `name=<instance>-<idx>`
  - service: `name=<instance>-<idx>`
  - configmap v2: `name=<instance>-<idx>-cm-v2`
  - configmap env: `name=<instance>-<idx>-cm-env`
  - chainlinknode: `name=<instance>-<idx>`
    - secret db: `name=<instance>-<idx>-db`
    - secret creds: `name=<instance>-<idx>-creds`
    - secret v2: `name=<instance>-<idx>-v2`
  - analysis template (optional): `name=<instance>-<idx>-hc`
  - service preview (optional): `name=<instance>-<idx>-preview`
  - servicemonitor (optional): `name=<instance>-<idx>`
  - ingress (optional): `name=<instance>-<idx>`
  - service public (optional): `name=<instance>-<idx>-pub`
  - secrets user defined v2 (optional): `name=<instance>-<idx>-usr-v2`
  - oraclestore (optional): `name=<instance>-<idx>`

{{ template "chart.valuesSection" . }}
