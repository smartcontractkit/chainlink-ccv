package ccv

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"math/big"
	"net/http"
	"os"
	"path/filepath"
	"strconv"
	"strings"

	"github.com/BurntSushi/toml"
	"github.com/Masterminds/semver/v3"
	"github.com/ethereum/go-ethereum/common"
	"github.com/ethereum/go-ethereum/common/hexutil"
	"github.com/rs/zerolog"

	"github.com/smartcontractkit/chainlink-ccip/ccv/chains/evm/deployment/v1_7_0/operations/committee_verifier"
	"github.com/smartcontractkit/chainlink-ccv/devenv/cciptestinterfaces"
	"github.com/smartcontractkit/chainlink-ccv/devenv/internal/util"
	"github.com/smartcontractkit/chainlink-ccv/devenv/services"
	"github.com/smartcontractkit/chainlink-ccv/indexer/pkg/config"
	"github.com/smartcontractkit/chainlink-ccv/protocol"
	"github.com/smartcontractkit/chainlink-ccv/verifier/commit"
	"github.com/smartcontractkit/chainlink-deployments-framework/datastore"
	"github.com/smartcontractkit/chainlink-deployments-framework/deployment"
	"github.com/smartcontractkit/chainlink-testing-framework/framework"
	"github.com/smartcontractkit/chainlink-testing-framework/framework/clclient"
	"github.com/smartcontractkit/chainlink-testing-framework/framework/components/blockchain"
	"github.com/smartcontractkit/chainlink-testing-framework/framework/components/clnode"
	"github.com/smartcontractkit/chainlink-testing-framework/framework/components/jd"

	chainsel "github.com/smartcontractkit/chain-selectors"
	"github.com/smartcontractkit/chainlink-ccv/devenv/evm"
	ns "github.com/smartcontractkit/chainlink-testing-framework/framework/components/simple_node_set"
)

const (
	CommonCLNodesConfig = `
			[Log]
			JSONConsole = true
			Level = 'info'
			[Pyroscope]
			ServerAddress = 'http://host.docker.internal:4040'
			Environment = 'local'
			[WebServer]
			SessionTimeout = '999h0m0s'
			HTTPWriteTimeout = '3m'
			SecureCookies = false
			HTTPPort = 6688
			[WebServer.TLS]
			HTTPSPort = 0
			[WebServer.RateLimit]
			Authenticated = 5000
			Unauthenticated = 5000
			[JobPipeline]
			[JobPipeline.HTTPRequest]
			DefaultTimeout = '1m'
			[Log.File]
			MaxSize = '0b'
			[Feature]
			FeedsManager = true
			LogPoller = true
			UICSAKeys = true
			[OCR2]
			Enabled = true
			SimulateTransactions = false
			DefaultTransactionQueueDepth = 1
			[P2P.V2]
			Enabled = true
			ListenAddresses = ['0.0.0.0:6690']
`
	// This is to pick up the appropriate onchain signing key type from the OCR2 keys
	// generated by the CL nodes.
	// TODO: In the future we may wanna select different chain types for different destination chain
	// families.
	signingKeyChainType = "evm"
)

type Cfg struct {
	CLDF               CLDF                           `toml:"cldf"                  validate:"required"`
	Pricer             *services.PricerInput          `toml:"pricer" validate:"required"`
	Fake               *services.FakeInput            `toml:"fake"                  validate:"required"`
	Verifier           []*services.VerifierInput      `toml:"verifier"              validate:"required"`
	TokenVerifier      []*services.TokenVerifierInput `toml:"token_verifier"`
	Executor           []*services.ExecutorInput      `toml:"executor"              validate:"required"`
	Indexer            *services.IndexerInput         `toml:"indexer"               validate:"required"`
	Aggregator         []*services.AggregatorInput    `toml:"aggregator"            validate:"required"`
	JD                 *jd.Input                      `toml:"jd"                    validate:"required"`
	Blockchains        []*blockchain.Input            `toml:"blockchains"           validate:"required"`
	NodeSets           []*ns.Input                    `toml:"nodesets"              validate:"required"`
	CLNodesFundingETH  float64                        `toml:"cl_nodes_funding_eth"`
	CLNodesFundingLink float64                        `toml:"cl_nodes_funding_link"`
	// AggregatorEndpoints map the verifier qualifier to the aggregator URL for that verifier.
	AggregatorEndpoints map[string]string `toml:"aggregator_endpoints"`
	// AggregatorCACertFiles map the verifier qualifier to the CA cert file path for TLS verification.
	AggregatorCACertFiles map[string]string `toml:"aggregator_ca_cert_files"`
	IndexerEndpoint       string            `toml:"indexer_endpoint"`
}

// NewAggregatorClientForCommittee creates an AggregatorClient for the specified committee.
// It automatically handles TLS configuration, using the CA cert file if available (devenv),
// or falling back to system certs (staging/prod).
func (c *Cfg) NewAggregatorClientForCommittee(logger zerolog.Logger, committeeName string) (*AggregatorClient, error) {
	endpoint, ok := c.AggregatorEndpoints[committeeName]
	if !ok {
		return nil, fmt.Errorf("no aggregator endpoint found for committee %s", committeeName)
	}

	caCertFile := c.AggregatorCACertFiles[committeeName]
	return NewAggregatorClient(logger, endpoint, caCertFile)
}

// checkKeys performs basic sanity checks on the private key being used depending on which chain is in
// the provided configuration.
func checkKeys(in *Cfg) error {
	if getNetworkPrivateKey() != DefaultAnvilKey && in.Blockchains[0].ChainID == "1337" && in.Blockchains[1].ChainID == "2337" {
		return errors.New("you are trying to run simulated chains with a key that do not belong to Anvil, please run 'unset PRIVATE_KEY'")
	}
	if getNetworkPrivateKey() == DefaultAnvilKey && in.Blockchains[0].ChainID != "1337" && in.Blockchains[1].ChainID != "2337" {
		return errors.New("you are trying to run on real networks but is not using the Anvil private key, export your private key 'export PRIVATE_KEY=...'")
	}
	return nil
}

func NewProductConfigurationFromNetwork(typ string) (cciptestinterfaces.CCIP17ProductConfiguration, error) {
	switch typ {
	case "anvil":
		return evm.NewEmptyCCIP17EVM(), nil
	case "canton":
		// see devenv-evm implementation and add Canton
		return nil, errors.New("canton is not supported yet")
	default:
		return nil, errors.New("unknown devenv network type " + typ)
	}
}

// NewEnvironment creates a new CCIP CCV environment locally in Docker.
func NewEnvironment() (in *Cfg, err error) {
	ctx := context.Background()
	timeTrack := NewTimeTracker(Plog)

	// track environment startup result and time using getDX app
	defer func() {
		dxTracker := initDxTracker()
		sendStartupMetrics(dxTracker, err, timeTrack.SinceStart().Seconds())
	}()

	ctx = L.WithContext(ctx)
	if err = framework.DefaultNetwork(nil); err != nil {
		return nil, err
	}

	/////////////////////////////
	// START: Read Config toml //
	/////////////////////////////

	configs := strings.Split(os.Getenv(EnvVarTestConfigs), ",")
	if len(configs) > 1 {
		L.Warn().Msg("Multiple configuration files detected, this feature may be unsupported in the future.")
	}
	in, err = Load[Cfg](configs)
	if err != nil {
		return nil, fmt.Errorf("failed to load configuration: %w", err)
	}

	// Executor config...
	if in.Executor != nil {
		for _, exec := range in.Executor {
			services.ApplyExecutorDefaults(exec)
		}
	}

	/////////////////////////////
	// END: Read Config toml //
	/////////////////////////////

	// Start fake data provider. This isn't really used, but may be useful in the future.
	_, err = services.NewFake(in.Fake)
	if err != nil {
		return nil, fmt.Errorf("failed to create fake data provider: %w", err)
	}

	///////////////////////////////
	// START: Deploy blockchains //
	// The services crash if the RPC is not available.
	///////////////////////////////
	if err = checkKeys(in); err != nil {
		return nil, err
	}

	impls := make([]cciptestinterfaces.CCIP17ProductConfiguration, 0)
	for _, bc := range in.Blockchains {
		var impl cciptestinterfaces.CCIP17ProductConfiguration
		impl, err = NewProductConfigurationFromNetwork(bc.Type)
		if err != nil {
			return nil, err
		}
		impls = append(impls, impl)
	}
	for i, impl := range impls {
		_, err = impl.DeployLocalNetwork(ctx, in.Blockchains[i])
		if err != nil {
			return nil, fmt.Errorf("failed to deploy local networks: %w", err)
		}
	}
	/////////////////////////////
	// END: Deploy blockchains //
	/////////////////////////////

	///////////////////////////////////////////
	// START: Generate Aggregator Credentials //
	// Generate HMAC credentials for all aggregator clients before launching
	// CL nodes, so they can receive the credentials via secrets.
	///////////////////////////////////////////
	for _, agg := range in.Aggregator {
		if _, err := agg.EnsureClientCredentials(); err != nil {
			return nil, fmt.Errorf("failed to ensure client credentials for aggregator %s: %w", agg.CommitteeName, err)
		}
	}
	/////////////////////////////////////////
	// END: Generate Aggregator Credentials //
	/////////////////////////////////////////

	///////////////////////////////
	// START: Deploy Pricer service //
	///////////////////////////////
	if _, err := services.NewPricer(in.Pricer); err != nil {
		return nil, fmt.Errorf("failed to setup pricer service")
	}

	for i, impl := range impls {
		Plog.Info().Int("ImplIndex", i).Msg("Funding pricer key")
		err = impl.FundAddresses(
			ctx,
			in.Blockchains[i],
			[]protocol.UnknownAddress{common.HexToAddress(in.Pricer.Keystore.Address).Bytes()},
			big.NewInt(5),
		)
		if err != nil {
			return nil, fmt.Errorf("failed to fund pricer address: %w", err)
		}
		Plog.Info().Int("ImplIndex", i).Msg("Funded pricer address")
	}

	///////////////////////////////
	// END: Deploy Pricer service //
	///////////////////////////////

	////////////////////////////
	// START: Launch CL Nodes //
	// We launch the CL nodes first because they don't require any configuration from
	// the rest of the system to be up and running.
	// In addition, if we need to launch the nodes (i.e if some services are not standalone),
	// we need to launch the nodes first to get the onchain public keys which will then
	// be used to configure the rest of the system (aggregator, onchain committees, etc.).
	////////////////////////////

	timeTrack.Record("[infra] deploying CL nodes")
	onchainPublicKeys, err := launchCLNodes(ctx, in, impls, in.Verifier, in.Aggregator)
	if err != nil {
		return nil, fmt.Errorf("failed to launch CL nodes: %w", err)
	}
	timeTrack.Record("[infra] deployed CL nodes")

	//////////////////////////
	// END: Launch CL Nodes //
	//////////////////////////

	/////////////////////////////////////////////
	// START: Assign signing keys to verifiers //
	/////////////////////////////////////////////
	roundRobin := NewRoundRobinAssignment(onchainPublicKeys[signingKeyChainType])
	for i := range in.Verifier {
		ver := services.ApplyVerifierDefaults(*in.Verifier[i])

		switch ver.Mode {
		case services.CL:
			// in cl mode, we can pull in the pubkeys from the CL nodes that were launched
			// in an earlier step.
			index, publicKey := roundRobin.GetNext()
			ver.SigningKeyPublic = publicKey
			Plog.Info().
				Str("CommitteeName", ver.CommitteeName).
				Str("SigningKeyPublic", publicKey).
				Int("CurrentIndex", index).
				Msg("Assigning CL node signing key public to verifier")

		case services.Standalone:
			// deterministic key generation algorithm.
			ver.SigningKey = util.XXXNewVerifierPrivateKey(ver.CommitteeName, ver.NodeIndex)

			privateKey, err := commit.ReadPrivateKeyFromString(ver.SigningKey)
			if err != nil {
				return nil, fmt.Errorf("failed to load private key: %w", err)
			}
			_, publicKey, err := commit.NewECDSAMessageSigner(privateKey)
			if err != nil {
				return nil, fmt.Errorf("failed to create message signer: %w", err)
			}
			ver.SigningKeyPublic = publicKey.String()

		default:
			return nil, fmt.Errorf("unsupported verifier mode: %s", ver.Mode)
		}

		// Apply changes back to input.
		in.Verifier[i] = &ver
	}
	/////////////////////////////////////////////
	// END: Assign signing keys to verifiers //
	/////////////////////////////////////////////

	/////////////////////////////
	// START: Deploy contracts //
	/////////////////////////////
	var committees []cciptestinterfaces.OnChainCommittees
	{
		addrs := make(map[string][][]byte)

		for _, ver := range in.Verifier {
			// At this point, SigningKeyPublic must be assigned -- either by keygen either manually or by the CL node.
			addrs[ver.CommitteeName] = append(addrs[ver.CommitteeName], hexutil.MustDecode(ver.SigningKeyPublic))
		}

		for committeeName, signers := range addrs {
			committees = append(committees, cciptestinterfaces.OnChainCommittees{
				CommitteeQualifier: committeeName,
				Signers:            signers,
				// TODO: should this be pulled from the aggregator configuration, ThresholdPerSource?
				// And if nothing in there, default to len(signers)?
				Threshold: uint8(len(signers)),
			})
		}
	}

	var selectors []uint64
	var e *deployment.Environment
	// the CLDF datastore is not initialized at this point because contracts are not deployed yet.
	// it will get populated in the loop below.
	in.CLDF.Init()
	selectors, e, err = NewCLDFOperationsEnvironment(in.Blockchains, in.CLDF.DataStore)
	if err != nil {
		return nil, fmt.Errorf("creating CLDF operations environment: %w", err)
	}
	L.Info().Any("Selectors", selectors).Msg("Deploying for chain selectors")

	timeTrack.Record("[infra] deploying blockchains")
	ds := datastore.NewMemoryDataStore()
	for i, impl := range impls {
		var networkInfo chainsel.ChainDetails
		networkInfo, err = chainsel.GetChainDetailsByChainIDAndFamily(in.Blockchains[i].ChainID, chainsel.FamilyEVM)
		if err != nil {
			return nil, err
		}
		L.Info().Uint64("Selector", networkInfo.ChainSelector).Msg("Deployed chain selector")
		var dsi datastore.DataStore
		dsi, err = impl.DeployContractsForSelector(ctx, e, networkInfo.ChainSelector, committees)
		if err != nil {
			return nil, err
		}
		var addresses []datastore.AddressRef
		addresses, err = dsi.Addresses().Fetch()
		if err != nil {
			return nil, err
		}
		var a []byte
		a, err = json.Marshal(addresses)
		if err != nil {
			return nil, err
		}
		in.CLDF.AddAddresses(string(a))
		if err = ds.Merge(dsi); err != nil {
			return nil, err
		}
	}
	e.DataStore = ds.Seal()
	///////////////////////////
	// END: Deploy contracts //
	///////////////////////////

	/////////////////////////////////////////
	// START: Connect chains to each other //
	/////////////////////////////////////////

	for i, impl := range impls {
		var networkInfo chainsel.ChainDetails
		networkInfo, err = chainsel.GetChainDetailsByChainIDAndFamily(in.Blockchains[i].ChainID, chainsel.FamilyEVM)
		if err != nil {
			return nil, err
		}
		selsToConnect := make([]uint64, 0)
		for _, sel := range selectors {
			if sel != networkInfo.ChainSelector {
				selsToConnect = append(selsToConnect, sel)
			}
		}
		err = impl.ConnectContractsWithSelectors(ctx, e, networkInfo.ChainSelector, selsToConnect, committees)
		if err != nil {
			return nil, err
		}
	}

	/////////////////////////////////////////
	// END: Connect chains to each other //
	/////////////////////////////////////////

	///////////////////////////////
	// START: Launch aggregators //
	///////////////////////////////

	in.AggregatorEndpoints = make(map[string]string)
	in.AggregatorCACertFiles = make(map[string]string)

	// Generate shared TLS certificates for all aggregators
	var sharedTLSCerts *services.TLSCertPaths
	if len(in.Aggregator) > 0 {
		var allHostnames []string
		for _, agg := range in.Aggregator {
			nginxName := fmt.Sprintf("%s-%s", agg.CommitteeName, services.AggregatorNginxContainerNameSuffix)
			aggName := fmt.Sprintf("%s-%s", agg.CommitteeName, services.AggregatorContainerNameSuffix)
			allHostnames = append(allHostnames, nginxName, aggName)
		}
		allHostnames = append(allHostnames, "localhost")

		tlsCertDir := filepath.Join(util.CCVConfigDir(), "tls-shared")
		var err error
		sharedTLSCerts, err = services.GenerateTLSCertificates(allHostnames, tlsCertDir)
		if err != nil {
			return nil, fmt.Errorf("failed to generate shared TLS certificates: %w", err)
		}
	}

	for _, aggregatorInput := range in.Aggregator {
		aggregatorInput.SharedTLSCerts = sharedTLSCerts
		// Initialize proxy addresses from datastore.
		addrs, _ := e.DataStore.Addresses().Fetch()
		if aggregatorInput.CommitteeVerifierResolverAddresses == nil {
			aggregatorInput.CommitteeVerifierResolverAddresses = make(map[uint64]string)
		}
		for _, addr := range addrs {
			if addr.Qualifier != aggregatorInput.CommitteeName {
				continue
			}
			if addr.Type != "CommitteeVerifierResolver" {
				continue
			}
			if _, ok := aggregatorInput.CommitteeVerifierResolverAddresses[addr.ChainSelector]; ok {
				return nil, fmt.Errorf("duplicate committee verifier resolver address for committee %s on chain selector %d", aggregatorInput.CommitteeName, addr.ChainSelector)
			}
			aggregatorInput.CommitteeVerifierResolverAddresses[addr.ChainSelector] = addr.Address
		}

		out, err := services.NewAggregator(aggregatorInput, in.Verifier)
		if err != nil {
			return nil, fmt.Errorf("failed to create aggregator service for committee %s: %w", aggregatorInput.CommitteeName, err)
		}
		in.AggregatorEndpoints[aggregatorInput.CommitteeName] = out.ExternalHTTPSUrl
		if out.TLSCACertFile != "" {
			in.AggregatorCACertFiles[aggregatorInput.CommitteeName] = out.TLSCACertFile
		}
	}

	///////////////////////////////
	// START: Launch aggregators //
	///////////////////////////////

	///////////////////////////
	// START: Launch indexer //
	// start up the indexer after the aggregators are up to avoid spamming of errors
	// in the logs when it starts before the aggregators are up.
	///////////////////////////
	// Need to update the addresses in the indexer config due to contract deployment nondeterminism.
	for _, agg := range in.Aggregator {
		// XXX: in theory addresses should be matching across chains
		chain := in.Blockchains[0]
		chainInfo, err := chainsel.GetChainDetailsByChainIDAndFamily(chain.ChainID, chainsel.FamilyEVM)
		if err != nil {
			return nil, fmt.Errorf("failed to get chain details for chain %s: %w", chain.ChainID, err)
		}

		address, err := e.DataStore.Addresses().Get(
			datastore.NewAddressRefKey(
				chainInfo.ChainSelector,
				datastore.ContractType(committee_verifier.ResolverType),
				semver.MustParse(committee_verifier.Deploy.Version()),
				agg.CommitteeName,
			))
		if err != nil {
			return nil, fmt.Errorf("failed to get committee verifier resolver address for committee %s on chain %s: %w", agg.CommitteeName, chain.ChainID, err)
		}

		// find the verifier in the indexer config that references this aggregator
		idx := -1
		for i, ver := range in.Indexer.IndexerConfig.Verifiers {
			if strings.HasPrefix(ver.Address, agg.CommitteeName) {
				idx = i
				break
			}
		}

		if idx == -1 {
			return nil, fmt.Errorf("failed to find verifier in indexer config that references committee verifier resolver address for committee %s on chain %s", agg.CommitteeName, chain.ChainID)
		}

		in.Indexer.IndexerConfig.Verifiers[idx].IssuerAddresses = []string{
			address.Address,
		}

		// Update verifier address to use nginx TLS proxy
		if agg.Out != nil {
			in.Indexer.IndexerConfig.Verifiers[idx].Address = agg.Out.Address
		}

		Plog.Info().
			Str("committee", agg.CommitteeName).
			Str("address", address.Address).
			Msg("assigned issuer address to verifier in indexer config")
	}

	// Set TLS CA cert for indexer (all aggregators share the same CA)
	if sharedTLSCerts != nil {
		in.Indexer.TLSCACertFile = sharedTLSCerts.CACertFile
		// Update discovery config to use nginx TLS proxy
		if len(in.Aggregator) > 0 && in.Aggregator[0].Out != nil {
			in.Indexer.IndexerConfig.Discovery.Address = in.Aggregator[0].Out.Address
		}
	}

	// Inject generated credentials into indexer secrets for aggregator connections
	if in.Indexer.Secrets == nil {
		in.Indexer.Secrets = &config.SecretsConfig{
			Verifier: make(map[string]config.VerifierSecrets),
		}
	}
	if in.Indexer.Secrets.Verifier == nil {
		in.Indexer.Secrets.Verifier = make(map[string]config.VerifierSecrets)
	}

	// Discovery uses the first aggregator's indexer credentials
	if len(in.Aggregator) > 0 {
		if creds, ok := in.Aggregator[0].Out.GetCredentialsForClient("indexer"); ok {
			in.Indexer.Secrets.Discovery.APIKey = creds.APIKey
			in.Indexer.Secrets.Discovery.Secret = creds.Secret
		}
	}

	// Each verifier config needs credentials from its corresponding aggregator
	for idx, agg := range in.Aggregator {
		if creds, ok := agg.Out.GetCredentialsForClient("indexer"); ok {
			in.Indexer.Secrets.Verifier[strconv.Itoa(idx)] = config.VerifierSecrets{
				APIKey: creds.APIKey,
				Secret: creds.Secret,
			}
		}
	}

	indexerOut, err := services.NewIndexer(in.Indexer)
	if err != nil {
		return nil, fmt.Errorf("failed to create indexer service: %w", err)
	}

	in.IndexerEndpoint = indexerOut.ExternalHTTPURL

	/////////////////////////
	// END: Launch indexer //
	/////////////////////////

	/////////////////////////////
	// START: Launch executors //
	/////////////////////////////

	if len(in.Executor) > 0 {
		execs, err := services.ResolveContractsForExecutor(e.DataStore, in.Blockchains, in.Executor)
		if err != nil {
			return nil, fmt.Errorf("failed to lookup contracts for executor: %w", err)
		}
		execs, err = services.SetExecutorPoolAndID(execs)
		if err != nil {
			return nil, fmt.Errorf("failed to set executor pool and ID: %w", err)
		}
		execs, err = services.SetTransmitterPrivateKey(execs)
		if err != nil {
			return nil, fmt.Errorf("failed to set transmitter private key: %w", err)
		}

		// fund the keys used by the executors to send transactions in standalone mode.
		addresses := make([]protocol.UnknownAddress, 0, len(execs))
		for _, exec := range execs {
			addresses = append(addresses, exec.GetTransmitterAddress())
		}
		Plog.Info().Any("Addresses", addresses).Int("ImplsLen", len(impls)).Msg("Funding executors")
		for i, impl := range impls {
			Plog.Info().Int("ImplIndex", i).Msg("Funding executor")
			err = impl.FundAddresses(ctx, in.Blockchains[i], addresses, big.NewInt(5))
			if err != nil {
				return nil, fmt.Errorf("failed to fund addresses for executors: %w", err)
			}
			Plog.Info().Int("ImplIndex", i).Msg("Funded executors")
		}

		in.Executor = execs
	}
	_, err = launchStandaloneExecutors(in.Executor)
	if err != nil {
		return nil, fmt.Errorf("failed to create standalone executor: %w", err)
	}

	///////////////////////////
	// END: Launch executors //
	///////////////////////////

	/////////////////////////////
	// START: Launch verifiers //
	/////////////////////////////
	// Populate verifier input with contract addresses from the CLDF datastore.
	for i := range in.Verifier {
		ver, err := services.ResolveContractsForVerifier(e.DataStore, in.Blockchains, *in.Verifier[i])
		if err != nil {
			return nil, fmt.Errorf("failed to lookup contracts for verifier %s: %w", in.Verifier[i].CommitteeName, err)
		}

		// Find aggregator output for this verifier's committee
		for _, agg := range in.Aggregator {
			if agg.CommitteeName == ver.CommitteeName && agg.Out != nil {
				if ver.InsecureAggregatorConnection {
					// CL node tests can't inject certs, use direct insecure connection
					ver.AggregatorAddress = agg.Out.ExternalHTTPUrl
				} else {
					ver.AggregatorAddress = agg.Out.Address
				}
				break
			}
		}
		if ver.AggregatorAddress == "" {
			if ver.InsecureAggregatorConnection {
				ver.AggregatorAddress = fmt.Sprintf("%s-aggregator:50051", ver.CommitteeName)
			} else {
				ver.AggregatorAddress = fmt.Sprintf("%s-aggregator-nginx:443", ver.CommitteeName)
			}
		}

		// Use shared TLS CA cert for all verifiers (not needed for insecure connections)
		if sharedTLSCerts != nil && !ver.InsecureAggregatorConnection {
			ver.TLSCACertFile = sharedTLSCerts.CACertFile
		}

		// Apply changes back to input.
		in.Verifier[i] = &ver
	}

	_, err = launchStandaloneVerifiers(in)
	if err != nil {
		return nil, fmt.Errorf("failed to create standalone verifiers: %w", err)
	}

	/////////////////////////////
	// END: Launch verifiers //
	/////////////////////////////

	///////////////////////////////////
	// START: Launch token verifiers //
	///////////////////////////////////

	for i := range in.TokenVerifier {
		ver, err := services.ResolveContractsForTokenVerifier(e.DataStore, in.Blockchains, *in.TokenVerifier[i])
		if err != nil {
			return nil, fmt.Errorf("failed to lookup contracts %w", err)
		}

		in.TokenVerifier[i] = &ver
	}

	_, err = launchStandaloneTokenVerifiers(in)
	if err != nil {
		return nil, fmt.Errorf("failed to create standalone token verifiers: %w", err)
	}

	///////////////////////////////////
	// END: Launch token verifiers //
	///////////////////////////////////

	////////////////////////////////////////////////////
	// START: Create jobs for verifiers and executors //
	// Note that if they are started in standalone mode,
	// there would be no CL nodes and this would be a no-op.
	////////////////////////////////////////////////////

	err = createJobs(in, in.Verifier, in.Executor)
	if err != nil {
		return nil, fmt.Errorf("failed to create jobs: %w", err)
	}

	//////////////////////////////////////////////////
	// END: Create jobs for verifiers and executors //
	//////////////////////////////////////////////////

	timeTrack.Print()
	if err = PrintCLDFAddresses(in); err != nil {
		return nil, err
	}

	return in, Store(in)
}

// createJobs creates the jobs for the verifiers and executors on the CL nodes if they're in CL mode.
func createJobs(in *Cfg, vIn []*services.VerifierInput, executorIn []*services.ExecutorInput) error {
	// Exit early, there are no nodes configured.
	if len(in.NodeSets) == 0 {
		return nil
	}

	clClients := make([]*clclient.ChainlinkClient, 0)
	for _, ns := range in.NodeSets {
		nc, err := clclient.New(ns.Out.CLNodes)
		if err != nil {
			return fmt.Errorf("failed to connect CL node clients: %w", err)
		}
		clClients = append(clClients, nc...)
	}
	roundRobin := NewRoundRobinAssignment(clClients)
	for _, ver := range vIn {
		switch ver.Mode {
		case services.CL:
			index, clClient := roundRobin.GetNext()

			jobSpec, err := ver.GenerateJobSpec()
			if err != nil {
				return fmt.Errorf("failed to generate verifier config: %w", err)
			}
			jb, resp, err := clClient.CreateJobRaw(jobSpec)
			if err != nil {
				return fmt.Errorf("failed to create committee verifier job: %w", err)
			}
			if resp.StatusCode != http.StatusOK && resp.StatusCode != http.StatusCreated {
				return fmt.Errorf("failed to create committee verifier job: %s", resp.Status)
			}
			Plog.Info().
				Int("CurrentIndex", index).
				Any("CommitteeVerifierJob", jb).
				Msg("Created committee verifier job on node")
		case services.Standalone:
			continue
		}
	}

	for _, exec := range executorIn {
		switch exec.Mode {
		case services.CL:
			index, clClient := roundRobin.GetNext()

			jobSpec, err := exec.GenerateJobSpec()
			if err != nil {
				return fmt.Errorf("failed to generate executor config: %w", err)
			}

			jb, resp, err := clClient.CreateJobRaw(jobSpec)
			if err != nil {
				return fmt.Errorf("failed to create executor job: %w", err)
			}
			if resp.StatusCode != http.StatusOK && resp.StatusCode != http.StatusCreated {
				return fmt.Errorf("failed to create executor job: %s", resp.Status)
			}
			Plog.Info().
				Int("CurrentIndex", index).
				Any("ExecutorJob", jb).
				Msg("Created executor job on node")
		case services.Standalone:
			continue
		}
	}

	return nil
}

// launchCLNodes encapsulates the logic required to launch the core node. It may be better to wrap this in a service.
// It returns the onchain public keys for each chain type for each CL node.
func launchCLNodes(
	ctx context.Context,
	in *Cfg,
	impls []cciptestinterfaces.CCIP17ProductConfiguration,
	vIn []*services.VerifierInput,
	aggregators []*services.AggregatorInput,
) (map[string][]string, error) {
	aggByCommittee := make(map[string]*services.AggregatorInput)
	for _, agg := range aggregators {
		aggByCommittee[agg.CommitteeName] = agg
	}

	// Exit early, there are no nodes configured.
	if len(in.NodeSets) == 0 {
		return nil, nil
	}

	hasAService := false
	for _, ver := range in.Verifier {
		hasAService = hasAService || (ver.Mode == services.CL)
	}

	for _, exec := range in.Executor {
		hasAService = hasAService || (exec.Mode == services.CL)
	}

	// Exit early, there are no services configured to deploy on a CL node.
	if !hasAService {
		return nil, nil
	}

	var err error
	clChainConfigs := make([]string, 0)
	clChainConfigs = append(clChainConfigs, CommonCLNodesConfig)
	for i, impl := range impls {
		var clChainConfig string
		clChainConfig, err = impl.ConfigureNodes(ctx, in.Blockchains[i])
		if err != nil {
			return nil, fmt.Errorf("failed to deploy local networks: %w", err)
		}
		clChainConfigs = append(clChainConfigs, clChainConfig)
	}
	allConfigs := strings.Join(clChainConfigs, "\n")

	for _, nodeSet := range in.NodeSets {
		for _, nodeSpec := range nodeSet.NodeSpecs {
			nodeSpec.Node.TestConfigOverrides = allConfigs
		}
	}

	// set the secret keys of the aggregator for each verifier ID
	nodeSpecs := make([]*clnode.Input, 0)
	for _, nodeSet := range in.NodeSets {
		nodeSpecs = append(nodeSpecs, nodeSet.NodeSpecs...)
	}
	nodeRoundRobin := NewRoundRobinAssignment(nodeSpecs)
	aggSecretsPerNode := make(map[int][]AggregatorSecret)
	for _, ver := range vIn {
		index, _ := nodeRoundRobin.GetNext()
		agg := aggByCommittee[ver.CommitteeName]
		apiKeys, err := agg.GetAPIKeys()
		if err != nil {
			return nil, fmt.Errorf("failed to get API keys for aggregator %s: %w", agg.CommitteeName, err)
		}
		Plog.Info().
			Int("index", index).
			Str("verifier", ver.ContainerName).
			Str("committee", ver.CommitteeName).
			Any("apiKeys", apiKeys).
			Msg("getting API keys for verifier")
		var found bool
		for _, apiClient := range apiKeys {
			if apiClient.ClientID == ver.ContainerName {
				if len(apiClient.APIKeyPairs) == 0 {
					return nil, fmt.Errorf("no API key pairs found for client %s", apiClient.ClientID)
				}
				apiKeyPair := apiClient.APIKeyPairs[0]
				aggSecretsPerNode[index] = append(aggSecretsPerNode[index], AggregatorSecret{
					VerifierID: ver.ContainerName,
					APIKey:     apiKeyPair.APIKey,
					APISecret:  apiKeyPair.Secret,
				})
				found = true
				break
			}
		}
		if !found {
			return nil, fmt.Errorf("failed to find API client for verifier %s on node %d", ver.ContainerName, index)
		}
	}
	idx := 0
	for i, nodeSet := range in.NodeSets {
		for j := range nodeSet.NodeSpecs {
			if len(aggSecretsPerNode[idx]) == 0 {
				return nil, fmt.Errorf("no aggregator secrets found for node %d", i+j)
			}

			secrets := Secrets{
				CCV: CCVSecrets{
					AggregatorSecrets: aggSecretsPerNode[idx],
				},
			}
			secretsToml, err := secrets.TomlString()
			if err != nil {
				return nil, fmt.Errorf("failed to marshal CCV secrets to TOML: %w", err)
			}
			in.NodeSets[i].NodeSpecs[j].Node.TestSecretsOverrides = secretsToml
			Plog.Info().Msg("overrode secrets for node")
			fmt.Println(secretsToml)
			idx++
		}
	}
	Plog.Info().Msg("Nodes network configuration is generated")

	for _, nodeset := range in.NodeSets {
		_, err = ns.NewSharedDBNodeSet(nodeset, nil)
		if err != nil {
			return nil, fmt.Errorf("failed to create new shared db node set: %w", err)
		}
	}
	// Fund nodes...
	for i, impl := range impls {
		if err = impl.FundNodes(ctx, in.NodeSets, in.Blockchains[i], big.NewInt(1), big.NewInt(5)); err != nil {
			return nil, fmt.Errorf("failed to fund nodes: %w", err)
		}
	}

	// Configured keys on CL nodes
	clClients := make([]*clclient.ChainlinkClient, 0)

	for _, ns := range in.NodeSets {
		nc, err := clclient.New(ns.Out.CLNodes)
		if err != nil {
			return nil, fmt.Errorf("failed to connect CL node clients")
		}
		clClients = append(clClients, nc...)
	}
	onchainPublicKeys := make(map[string][]string) // chainType -> onchain public keys
	for _, cc := range clClients {
		ocr2Keys, err := cc.MustReadOCR2Keys()
		if err != nil {
			return nil, fmt.Errorf("failed to read OCR2 keys: %w", err)
		}
		for _, keyData := range ocr2Keys.Data {
			onchainPublicKeys[keyData.Attributes.ChainType] = append(
				onchainPublicKeys[keyData.Attributes.ChainType],
				prefixWith0xIfNeeded(
					// the stringified keys have ocr2on_<chainType>_ as a prefix prior to actually getting
					// the hex public key, so needs to be trimmed first before we can use it everywhere
					// else.
					strings.TrimPrefix(
						keyData.Attributes.OnChainPublicKey,
						fmt.Sprintf("ocr2on_%s_", keyData.Attributes.ChainType),
					),
				),
			)
		}
		Plog.Info().Any("OCR2Keys", ocr2Keys.Data).Msg("Read OCR2 keys from node")
	}

	Plog.Info().Any("OnchainPublicKeys", onchainPublicKeys).Msg("Onchain public keys for all nodes")

	return onchainPublicKeys, nil
}

func launchStandaloneExecutors(in []*services.ExecutorInput) ([]*services.ExecutorOutput, error) {
	var outs []*services.ExecutorOutput
	// Start standalone executors if they are in standalone mode.
	for _, exec := range in {
		if exec != nil && exec.Mode == services.Standalone {
			out, err := services.NewExecutor(exec)
			if err != nil {
				return nil, fmt.Errorf("failed to create executor service: %w", err)
			}
			outs = append(outs, out)
		}
	}
	return outs, nil
}

func launchStandaloneVerifiers(in *Cfg) ([]*services.VerifierOutput, error) {
	aggregatorOutputByCommittee := make(map[string]*services.AggregatorOutput)
	for _, agg := range in.Aggregator {
		if agg.Out != nil {
			aggregatorOutputByCommittee[agg.CommitteeName] = agg.Out
		}
	}

	var outs []*services.VerifierOutput
	// Start standalone verifiers if in standalone mode.
	for _, ver := range in.Verifier {
		if ver.Mode == services.Standalone {
			if aggOut, ok := aggregatorOutputByCommittee[ver.CommitteeName]; ok {
				ver.AggregatorOutput = aggOut
			}
			out, err := services.NewVerifier(ver)
			if err != nil {
				return nil, fmt.Errorf("failed to create verifier service: %w", err)
			}
			ver.Out = out
			outs = append(outs, out)
		}
	}
	return outs, nil
}

func launchStandaloneTokenVerifiers(in *Cfg) ([]*services.TokenVerifierOutput, error) {
	var outs []*services.TokenVerifierOutput
	for _, ver := range in.TokenVerifier {
		if ver.Mode == services.Standalone {
			out, err := services.NewTokenVerifier(ver)
			if err != nil {
				return nil, fmt.Errorf("failed to create token verifier service: %w", err)
			}
			outs = append(outs, out)
		}
	}
	return outs, nil
}

func prefixWith0xIfNeeded(s string) string {
	if strings.HasPrefix(s, "0x") {
		return s
	}
	return "0x" + s
}

// Assignment represents drawing from a list of items without replacement,
// until all items have been drawn. At that point, the assignment will repeat.
// Round robin is an example of such an assignment strategy.
// TODO: probably not the right abstraction but is sufficient for now?
type Assignment[T any] interface {
	// GetNext returns the next item in the assignment.
	GetNext() (index int, item T)
}

// RoundRobinAssignment returns the next item in a round robin fashion.
type RoundRobinAssignment[T any] struct {
	items []T
	index int
}

// NewRoundRobinAssignment creates a new round robin assignment.
func NewRoundRobinAssignment[T any](items []T) Assignment[T] {
	return &RoundRobinAssignment[T]{items: items, index: 0}
}

// GetNext returns the next item in the round robin assignment.
func (a *RoundRobinAssignment[T]) GetNext() (int, T) {
	defer func() { a.index = (a.index + 1) % len(a.items) }()
	return a.index, a.items[a.index]
}

// TODO: this is copied from the toml secret structures in the CL node.
// We can't really import anything from there so this duplication is
// currently necessary.
type Secrets struct {
	CCV CCVSecrets `toml:",omitempty"`
}

func (c *Secrets) TomlString() (string, error) {
	data, err := toml.Marshal(c)
	if err != nil {
		return "", fmt.Errorf("failed to marshal CCV secrets to TOML: %w", err)
	}
	return string(data), nil
}

type CCVSecrets struct {
	AggregatorSecrets []AggregatorSecret `toml:",omitempty"`
	IndexerSecret     *IndexerSecret     `toml:",omitempty"`
}

type AggregatorSecret struct {
	VerifierID string `toml:",omitempty"`
	APIKey     string `toml:",omitempty"`
	APISecret  string `toml:",omitempty"`
}

type IndexerSecret struct {
	APIKey    string `toml:",omitempty"`
	APISecret string `toml:",omitempty"`
}
