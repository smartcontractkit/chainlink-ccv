package ccv

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"math/big"
	"net/http"
	"os"
	"strings"

	"github.com/BurntSushi/toml"
	"github.com/Masterminds/semver/v3"
	"github.com/ethereum/go-ethereum/common/hexutil"

	"github.com/smartcontractkit/chainlink-ccip/ccv/chains/evm/deployment/v1_7_0/operations/committee_verifier"
	"github.com/smartcontractkit/chainlink-ccv/devenv/cciptestinterfaces"
	"github.com/smartcontractkit/chainlink-ccv/devenv/internal/util"
	"github.com/smartcontractkit/chainlink-ccv/devenv/services"
	"github.com/smartcontractkit/chainlink-ccv/protocol"
	"github.com/smartcontractkit/chainlink-ccv/verifier/commit"
	"github.com/smartcontractkit/chainlink-deployments-framework/datastore"
	"github.com/smartcontractkit/chainlink-deployments-framework/deployment"
	"github.com/smartcontractkit/chainlink-testing-framework/framework"
	"github.com/smartcontractkit/chainlink-testing-framework/framework/clclient"
	"github.com/smartcontractkit/chainlink-testing-framework/framework/components/blockchain"
	"github.com/smartcontractkit/chainlink-testing-framework/framework/components/jd"

	chainsel "github.com/smartcontractkit/chain-selectors"
	"github.com/smartcontractkit/chainlink-ccv/devenv/evm"
	ns "github.com/smartcontractkit/chainlink-testing-framework/framework/components/simple_node_set"
)

const (
	CommonCLNodesConfig = `
			[Log]
			JSONConsole = true
			Level = 'info'
			[Pyroscope]
			ServerAddress = 'http://host.docker.internal:4040'
			Environment = 'local'
			[WebServer]
			SessionTimeout = '999h0m0s'
			HTTPWriteTimeout = '3m'
			SecureCookies = false
			HTTPPort = 6688
			[WebServer.TLS]
			HTTPSPort = 0
			[WebServer.RateLimit]
			Authenticated = 5000
			Unauthenticated = 5000
			[JobPipeline]
			[JobPipeline.HTTPRequest]
			DefaultTimeout = '1m'
			[Log.File]
			MaxSize = '0b'
			[Feature]
			FeedsManager = true
			LogPoller = true
			UICSAKeys = true
			[OCR2]
			Enabled = true
			SimulateTransactions = false
			DefaultTransactionQueueDepth = 1
			[P2P.V2]
			Enabled = true
			ListenAddresses = ['0.0.0.0:6690']
`
	// This is to pick up the appropriate onchain signing key type from the OCR2 keys
	// generated by the CL nodes.
	// TODO: In the future we may wanna select different chain types for different destination chain
	// families.
	signingKeyChainType = "evm"
)

type Cfg struct {
	Mode               services.Mode               `toml:"mode"`
	CLDF               CLDF                        `toml:"cldf"                  validate:"required"`
	JD                 *jd.Input                   `toml:"jd"                    validate:"required"`
	Fake               *services.FakeInput         `toml:"fake"                  validate:"required"`
	Verifier           []*services.VerifierInput   `toml:"verifier"              validate:"required"`
	Executor           []*services.ExecutorInput   `toml:"executor"              validate:"required"`
	Indexer            *services.IndexerInput      `toml:"indexer"               validate:"required"`
	Aggregator         []*services.AggregatorInput `toml:"aggregator"            validate:"required"`
	Blockchains        []*blockchain.Input         `toml:"blockchains"           validate:"required"`
	NodeSets           []*ns.Input                 `toml:"nodesets"              validate:"required"`
	CLNodesFundingETH  float64                     `toml:"cl_nodes_funding_eth"`
	CLNodesFundingLink float64                     `toml:"cl_nodes_funding_link"`
}

func checkKeys(in *Cfg) error {
	if getNetworkPrivateKey() != DefaultAnvilKey && in.Blockchains[0].ChainID == "1337" && in.Blockchains[1].ChainID == "2337" {
		return errors.New("you are trying to run simulated chains with a key that do not belong to Anvil, please run 'unset PRIVATE_KEY'")
	}
	if getNetworkPrivateKey() == DefaultAnvilKey && in.Blockchains[0].ChainID != "1337" && in.Blockchains[1].ChainID != "2337" {
		return errors.New("you are trying to run on real networks but is not using the Anvil private key, export your private key 'export PRIVATE_KEY=...'")
	}
	return nil
}

func NewProductConfigurationFromNetwork(typ string) (cciptestinterfaces.CCIP17ProductConfiguration, error) {
	switch typ {
	case "anvil":
		return evm.NewEmptyCCIP17EVM(), nil
	case "canton":
		// see devenv-evm implementation and add Canton
		return nil, nil
	default:
		return nil, errors.New("unknown devenv network type " + typ)
	}
}

// NewEnvironment creates a new CCIP CCV environment either locally in Docker or remotely in K8s.
func NewEnvironment() (in *Cfg, err error) {
	ctx := context.Background()
	timeTrack := NewTimeTracker(Plog)

	// track environment startup result and time using getDX app
	defer func() {
		dxTracker := initDxTracker()
		sendStartupMetrics(dxTracker, err, timeTrack.SinceStart().Seconds())
	}()

	ctx = L.WithContext(ctx)
	if err = framework.DefaultNetwork(nil); err != nil {
		return nil, err
	}

	configs := strings.Split(os.Getenv(EnvVarTestConfigs), ",")
	if len(configs) > 1 {
		L.Warn().Msg("Multiple configuration files detected, this feature may be unsupported in the future.")
	}
	in, err = Load[Cfg](configs)
	if err != nil {
		return nil, fmt.Errorf("failed to load configuration: %w", err)
	}

	///////////////////////////////
	// Start: Initialize Configs //
	///////////////////////////////

	// Override the default config to "cl"...
	if in.Mode == "" {
		in.Mode = services.Standalone
	}

	// Executor config...
	if in.Executor != nil {
		for _, exec := range in.Executor {
			services.ApplyExecutorDefaults(exec)
		}
	}

	/////////////////////////////
	// End: Initialize Configs //
	/////////////////////////////

	if err = checkKeys(in); err != nil {
		return nil, err
	}

	// Start fake data provider. This isn't really used, but may be useful in the future.
	_, err = services.NewFake(in.Fake)
	if err != nil {
		return nil, fmt.Errorf("failed to create fake data provider: %w", err)
	}

	// Start blockchains, the services crash if the RPC is not available.
	impls := make([]cciptestinterfaces.CCIP17ProductConfiguration, 0)
	for _, bc := range in.Blockchains {
		var impl cciptestinterfaces.CCIP17ProductConfiguration
		impl, err = NewProductConfigurationFromNetwork(bc.Type)
		if err != nil {
			return nil, err
		}
		impls = append(impls, impl)
	}
	for i, impl := range impls {
		_, err = impl.DeployLocalNetwork(ctx, in.Blockchains[i])
		if err != nil {
			return nil, fmt.Errorf("failed to deploy local networks: %w", err)
		}
	}

	////////////////////////////
	// Start: Launch CL Nodes //
	// We launch the CL nodes first because they don't require any configuration from
	// the rest of the system to be up and running.
	// In addition, if we need to launch the nodes (i.e if some services are not standalone),
	// we need to launch the nodes first to get the onchain public keys which will then
	// be used to configure the rest of the system (aggregator, onchain committees, etc.).
	////////////////////////////

	timeTrack.Record("[infra] deploying CL nodes")
	onchainPublicKeys, err := launchCLNodes(ctx, in, impls, in.Verifier, in.Aggregator)
	if err != nil {
		return nil, fmt.Errorf("failed to launch CL nodes: %w", err)
	}
	timeTrack.Record("[infra] deployed CL nodes")

	//////////////////////////
	// End: Launch CL Nodes //
	//////////////////////////

	// Verifier configs...
	roundRobin := NewRoundRobinAssignment(onchainPublicKeys[signingKeyChainType])
	for i := range in.Verifier {
		ver := services.ApplyVerifierDefaults(*in.Verifier[i])

		switch ver.Mode {
		case services.CL:
			// in cl mode, we can pull in the pubkeys from the CL nodes that were launched
			// in an earlier step.
			index, publicKey := roundRobin.GetNext()
			ver.SigningKeyPublic = publicKey
			Plog.Info().
				Str("CommitteeName", ver.CommitteeName).
				Str("SigningKeyPublic", publicKey).
				Int("CurrentIndex", index).
				Msg("Assigning CL node signing key public to verifier")

		case services.Standalone:
			// deterministic key generation algorithm.
			ver.SigningKey = util.XXXNewVerifierPrivateKey(ver.CommitteeName, ver.NodeIndex)

			privateKey, err := commit.ReadPrivateKeyFromString(ver.SigningKey)
			if err != nil {
				return nil, fmt.Errorf("failed to load private key: %w", err)
			}
			_, publicKey, err := commit.NewECDSAMessageSigner(privateKey)
			if err != nil {
				return nil, fmt.Errorf("failed to create message signer: %w", err)
			}
			ver.SigningKeyPublic = publicKey.String()

		default:
			return nil, fmt.Errorf("unsupported verifier mode: %s", ver.Mode)
		}

		// Apply changes back to input.
		in.Verifier[i] = &ver
	}

	// JD is not currently used.
	/*
		prodJDImage := os.Getenv("JD_IMAGE")

		if in.JD != nil {
			if prodJDImage != "" {
				in.JD.Image = prodJDImage
			}
			if len(in.JD.Image) == 0 {
				Plog.Warn().Msg("No JD image provided, skipping JD service startup")
			} else {
				_, err = jd.NewJD(in.JD)
				if err != nil {
					return nil, fmt.Errorf("failed to create JD service: %w", err)
				}
			}
		} else {
			Plog.Warn().Msg("No JD configuration provided, skipping JD service startup")
		}
	*/

	timeTrack.Record("[infra] deploying blockchains")

	/////////////////////////////
	// Start: Deploy contracts //
	/////////////////////////////

	// TODO: When job specs are supported, contract deploy needs to happen after CL nodes are up (and keys are
	// generated) and before the services have been started.

	var committees []cciptestinterfaces.OnChainCommittees
	{
		addrs := make(map[string][][]byte)

		for _, ver := range in.Verifier {
			// At this point, SigningKeyPublic must be assigned -- either by keygen either manually or by the CL node.
			addrs[ver.CommitteeName] = append(addrs[ver.CommitteeName], hexutil.MustDecode(ver.SigningKeyPublic))
		}

		for committeeName, signers := range addrs {
			committees = append(committees, cciptestinterfaces.OnChainCommittees{
				CommitteeQualifier: committeeName,
				Signers:            signers,
				Threshold:          uint8(len(signers)),
			})
		}
	}

	var selectors []uint64
	var e *deployment.Environment
	// the CLDF datastore is not initialized at this point because contracts are not deployed yet.
	// it will get populated in the loop below.
	in.CLDF.Init()
	selectors, e, err = NewCLDFOperationsEnvironment(in.Blockchains, in.CLDF.DataStore)
	if err != nil {
		return nil, fmt.Errorf("creating CLDF operations environment: %w", err)
	}
	L.Info().Any("Selectors", selectors).Msg("Deploying for chain selectors")

	ds := datastore.NewMemoryDataStore()
	for i, impl := range impls {
		var networkInfo chainsel.ChainDetails
		networkInfo, err = chainsel.GetChainDetailsByChainIDAndFamily(in.Blockchains[i].ChainID, chainsel.FamilyEVM)
		if err != nil {
			return nil, err
		}
		L.Info().Uint64("Selector", networkInfo.ChainSelector).Msg("Deployed chain selector")
		var dsi datastore.DataStore
		dsi, err = impl.DeployContractsForSelector(ctx, e, networkInfo.ChainSelector, committees)
		if err != nil {
			return nil, err
		}
		var addresses []datastore.AddressRef
		addresses, err = dsi.Addresses().Fetch()
		if err != nil {
			return nil, err
		}
		var a []byte
		a, err = json.Marshal(addresses)
		if err != nil {
			return nil, err
		}
		in.CLDF.AddAddresses(string(a))
		if err = ds.Merge(dsi); err != nil {
			return nil, err
		}
	}
	e.DataStore = ds.Seal()

	for i, impl := range impls {
		var networkInfo chainsel.ChainDetails
		networkInfo, err = chainsel.GetChainDetailsByChainIDAndFamily(in.Blockchains[i].ChainID, chainsel.FamilyEVM)
		if err != nil {
			return nil, err
		}
		selsToConnect := make([]uint64, 0)
		for _, sel := range selectors {
			if sel != networkInfo.ChainSelector {
				selsToConnect = append(selsToConnect, sel)
			}
		}
		err = impl.ConnectContractsWithSelectors(ctx, e, networkInfo.ChainSelector, selsToConnect, committees)
		if err != nil {
			return nil, err
		}
	}
	///////////////////////////
	// END: Deploy contracts //
	///////////////////////////

	///////////////////////////////////////
	// Start: Launch standalone services //
	///////////////////////////////////////

	// Start aggregators.
	for _, aggregatorInput := range in.Aggregator {
		// Initialize proxy addresses from datastore.
		addrs, _ := e.DataStore.Addresses().Fetch()
		if aggregatorInput.CommitteeVerifierResolverProxyAddresses == nil {
			aggregatorInput.CommitteeVerifierResolverProxyAddresses = make(map[uint64]string)
		}
		for _, addr := range addrs {
			if addr.Qualifier != aggregatorInput.CommitteeName {
				continue
			}
			if addr.Type != "CommitteeVerifierResolverProxy" {
				continue
			}
			if _, ok := aggregatorInput.CommitteeVerifierResolverProxyAddresses[addr.ChainSelector]; ok {
				return nil, fmt.Errorf("duplicate committee verifier resolver proxy address for committee %s on chain selector %d", aggregatorInput.CommitteeName, addr.ChainSelector)
			}
			aggregatorInput.CommitteeVerifierResolverProxyAddresses[addr.ChainSelector] = addr.Address
		}

		_, err = services.NewAggregator(aggregatorInput, in.Verifier)
		if err != nil {
			return nil, fmt.Errorf("failed to create aggregator service for committee %s: %w", aggregatorInput.CommitteeName, err)
		}
	}

	// Start indexer.
	// start up the indexer after the aggregators are up to avoid spamming of errors
	// in the logs when it starts before the aggregators are up.
	// Need to update the addresses in the indexer config due to contract deployment nondeterminism.
	for _, agg := range in.Aggregator {
		// XXX: in theory addresses should be matching across chains
		chain := in.Blockchains[0]
		chainInfo, err := chainsel.GetChainDetailsByChainIDAndFamily(chain.ChainID, chainsel.FamilyEVM)
		if err != nil {
			return nil, fmt.Errorf("failed to get chain details for chain %s: %w", chain.ChainID, err)
		}

		address, err := e.DataStore.Addresses().Get(
			datastore.NewAddressRefKey(
				chainInfo.ChainSelector,
				datastore.ContractType(committee_verifier.ResolverProxyType),
				semver.MustParse(committee_verifier.Deploy.Version()),
				agg.CommitteeName,
			))
		if err != nil {
			return nil, fmt.Errorf("failed to get committee verifier resolver proxy address for committee %s on chain %s: %w", agg.CommitteeName, chain.ChainID, err)
		}

		// find the verifier in the indexer config that references this aggregator
		idx := -1
		for i, ver := range in.Indexer.IndexerConfig.Verifiers {
			if strings.HasPrefix(ver.Address, agg.CommitteeName) {
				idx = i
				break
			}
		}

		if idx == -1 {
			return nil, fmt.Errorf("failed to find verifier in indexer config that references committee verifier resolver proxy address for committee %s on chain %s", agg.CommitteeName, chain.ChainID)
		}

		in.Indexer.IndexerConfig.Verifiers[idx].IssuerAddresses = []string{
			address.Address,
		}

		Plog.Info().
			Str("committee", agg.CommitteeName).
			Str("address", address.Address).
			Msg("assigned issuer address to verifier in indexer config")
	}
	_, err = services.NewIndexer(in.Indexer)
	if err != nil {
		return nil, fmt.Errorf("failed to create indexer service: %w", err)
	}

	if len(in.Executor) > 0 {
		execs, err := services.ResolveContractsForExecutor(e.DataStore, in.Blockchains, in.Executor)
		if err != nil {
			return nil, fmt.Errorf("failed to lookup contracts for executor: %w", err)
		}
		execs, err = services.SetExecutorPoolAndID(execs)
		if err != nil {
			return nil, fmt.Errorf("failed to set executor pool and ID: %w", err)
		}
		execs, err = services.SetTransmitterPrivateKey(execs)
		if err != nil {
			return nil, fmt.Errorf("failed to set transmitter private key: %w", err)
		}

		// fund the keys used by the executors to send transactions in standalone mode.
		addresses := make([]protocol.UnknownAddress, 0, len(execs))
		for _, exec := range execs {
			addresses = append(addresses, exec.GetTransmitterAddress())
		}
		Plog.Info().Any("Addresses", addresses).Int("ImplsLen", len(impls)).Msg("Funding executors")
		for i, impl := range impls {
			Plog.Info().Int("ImplIndex", i).Msg("Funding executor")
			err = impl.FundAddresses(ctx, in.Blockchains[i], addresses, big.NewInt(5))
			if err != nil {
				return nil, fmt.Errorf("failed to fund addresses for executors: %w", err)
			}
			Plog.Info().Int("ImplIndex", i).Msg("Funded executors")
		}

		in.Executor = execs
	}
	_, err = launchStandaloneExecutors(in.Executor)
	if err != nil {
		return nil, fmt.Errorf("failed to create standalone executor: %w", err)
	}

	// Populate verifier input with contract addresses from the CLDF datastore.
	for i := range in.Verifier {
		ver, err := services.ResolveContractsForVerifier(e.DataStore, in.Blockchains, *in.Verifier[i])
		if err != nil {
			return nil, fmt.Errorf("failed to lookup contracts for verifier %s: %w", in.Verifier[i].CommitteeName, err)
		}

		ver.AggregatorAddress = fmt.Sprintf("%s-aggregator:50051", ver.CommitteeName)

		// Apply changes back to input.
		in.Verifier[i] = &ver
	}

	_, err = launchStandaloneVerifiers(in)
	if err != nil {
		return nil, fmt.Errorf("failed to create standalone verifiers: %w", err)
	}

	/////////////////////////////////////
	// End: Launch standalone services //
	/////////////////////////////////////

	err = createJobs(in, in.Verifier, in.Executor)
	if err != nil {
		return nil, fmt.Errorf("failed to create jobs: %w", err)
	}

	timeTrack.Print()
	if err = PrintCLDFAddresses(in); err != nil {
		return nil, err
	}

	return in, Store(in)
}

// createJobs creates the jobs for the verifiers and executors on the CL nodes if they're in CL mode.
func createJobs(in *Cfg, vIn []*services.VerifierInput, executorIn []*services.ExecutorInput) error {
	// Exit early, there are no nodes configured.
	if len(in.NodeSets) == 0 {
		return nil
	}

	clClients, err := clclient.New(in.NodeSets[0].Out.CLNodes)
	if err != nil {
		return fmt.Errorf("failed to connect CL node clients: %w", err)
	}

	roundRobin := NewRoundRobinAssignment(clClients)
	for _, ver := range vIn {
		switch ver.Mode {
		case services.CL:
			index, clClient := roundRobin.GetNext()

			tomlConfig, err := ver.GenerateConfig()
			if err != nil {
				return fmt.Errorf("failed to generate verifier config: %w", err)
			}
			jb, resp, err := clClient.CreateJobRaw(committeeVerifierSpec(string(tomlConfig)))
			if err != nil {
				return fmt.Errorf("failed to create committee verifier job: %w", err)
			}
			if resp.StatusCode != http.StatusOK && resp.StatusCode != http.StatusCreated {
				return fmt.Errorf("failed to create committee verifier job: %s", resp.Status)
			}
			Plog.Info().
				Int("CurrentIndex", index).
				Any("CommitteeVerifierJob", jb).
				Msg("Created committee verifier job on node")
		case services.Standalone:
			continue
		}
	}

	for _, exec := range executorIn {
		switch exec.Mode {
		case services.CL:
			index, clClient := roundRobin.GetNext()

			tomlConfig, err := exec.GenerateConfig()
			if err != nil {
				return fmt.Errorf("failed to generate executor config: %w", err)
			}

			fmt.Println(tomlConfig)
			jb, resp, err := clClient.CreateJobRaw(executorSpec(string(tomlConfig)))
			if err != nil {
				return fmt.Errorf("failed to create executor job: %w", err)
			}
			if resp.StatusCode != http.StatusOK && resp.StatusCode != http.StatusCreated {
				return fmt.Errorf("failed to create executor job: %s", resp.Status)
			}
			Plog.Info().
				Int("CurrentIndex", index).
				Any("ExecutorJob", jb).
				Msg("Created executor job on node")
		case services.Standalone:
			continue
		}
	}

	return nil
}

func executorSpec(tomlConfig string) string {
	return fmt.Sprintf(
		`
schemaVersion = 1
type = "ccvexecutor"
executorConfig = """
%s
"""
`, tomlConfig,
	)
}

func committeeVerifierSpec(tomlConfig string) string {
	return fmt.Sprintf(
		`
schemaVersion = 1
type = "ccvcommitteeverifier"
committeeVerifierConfig = """
%s
"""
`, tomlConfig,
	)
}

// launchCLNodes encapsulates the logic required to launch the core node. It may be better to wrap this in a service.
// It returns the onchain public keys for each chain type for each CL node.
func launchCLNodes(
	ctx context.Context,
	in *Cfg,
	impls []cciptestinterfaces.CCIP17ProductConfiguration,
	vIn []*services.VerifierInput,
	aggregators []*services.AggregatorInput,
) (map[string][]string, error) {
	aggByCommittee := make(map[string]*services.AggregatorInput)
	for _, agg := range aggregators {
		aggByCommittee[agg.CommitteeName] = agg
	}

	// Exit early, there are no nodes configured.
	if len(in.NodeSets) == 0 {
		return nil, nil
	}

	hasAService := false
	for _, ver := range in.Verifier {
		hasAService = hasAService || (ver.Mode == services.CL)
	}

	for _, exec := range in.Executor {
		hasAService = hasAService || (exec.Mode == services.CL)
	}

	// Exit early, there are no services configured to deploy on a CL node.
	if !hasAService {
		return nil, nil
	}

	var err error
	clChainConfigs := make([]string, 0)
	clChainConfigs = append(clChainConfigs, CommonCLNodesConfig)
	for i, impl := range impls {
		var clChainConfig string
		clChainConfig, err = impl.ConfigureNodes(ctx, in.Blockchains[i])
		if err != nil {
			return nil, fmt.Errorf("failed to deploy local networks: %w", err)
		}
		clChainConfigs = append(clChainConfigs, clChainConfig)
	}
	allConfigs := strings.Join(clChainConfigs, "\n")
	for _, nodeSpec := range in.NodeSets[0].NodeSpecs {
		nodeSpec.Node.TestConfigOverrides = allConfigs
	}

	// set the secret keys of the aggregator for each verifier ID
	nodeRoundRobin := NewRoundRobinAssignment(in.NodeSets[0].NodeSpecs)
	aggSecretsPerNode := make(map[int][]AggregatorSecret)
	for _, ver := range vIn {
		index, _ := nodeRoundRobin.GetNext()
		agg := aggByCommittee[ver.CommitteeName]
		apiKeys, err := agg.GetAPIKeys()
		if err != nil {
			return nil, fmt.Errorf("failed to get API keys for aggregator %s: %w", agg.CommitteeName, err)
		}
		Plog.Info().
			Int("index", index).
			Str("verifier", ver.ContainerName).
			Str("committee", ver.CommitteeName).
			Any("apiKeys", apiKeys.Clients).
			Msg("getting API keys for verifier")
		var found bool
		for apiKey, apiClient := range apiKeys.Clients {
			if apiClient.ClientID == ver.ContainerName {
				aggSecretsPerNode[index] = append(aggSecretsPerNode[index], AggregatorSecret{
					VerifierID: ver.ContainerName,
					APIKey:     apiKey,
					APISecret:  apiClient.Secrets["primary"],
				})
				found = true
				break
			}
		}
		if !found {
			return nil, fmt.Errorf("failed to find API client for verifier %s on node %d", ver.ContainerName, index)
		}
	}

	for i := range in.NodeSets[0].NodeSpecs {
		if len(aggSecretsPerNode[i]) == 0 {
			return nil, fmt.Errorf("no aggregator secrets found for node %d", i)
		}

		secrets := Secrets{
			CCV: CCVSecrets{
				AggregatorSecrets: aggSecretsPerNode[i],
			},
		}
		secretsToml, err := secrets.TomlString()
		if err != nil {
			return nil, fmt.Errorf("failed to marshal CCV secrets to TOML: %w", err)
		}
		in.NodeSets[0].NodeSpecs[i].Node.TestSecretsOverrides = secretsToml
		Plog.Info().Msg("overrode secrets for node")
		fmt.Println(secretsToml)
	}
	Plog.Info().Msg("Nodes network configuration is generated")

	_, err = ns.NewSharedDBNodeSet(in.NodeSets[0], nil)
	if err != nil {
		return nil, fmt.Errorf("failed to create new shared db node set: %w", err)
	}

	// Fund nodes...
	for i, impl := range impls {
		if err = impl.FundNodes(ctx, in.NodeSets, in.Blockchains[i], big.NewInt(1), big.NewInt(5)); err != nil {
			return nil, fmt.Errorf("failed to fund nodes: %w", err)
		}
	}

	// Configured keys on CL nodes
	clClients, err := clclient.New(in.NodeSets[0].Out.CLNodes)
	if err != nil {
		return nil, fmt.Errorf("failed to connect CL node clients")
	}

	onchainPublicKeys := make(map[string][]string) // chainType -> onchain public keys
	for _, cc := range clClients {
		ocr2Keys, err := cc.MustReadOCR2Keys()
		if err != nil {
			return nil, fmt.Errorf("failed to read OCR2 keys: %w", err)
		}
		for _, keyData := range ocr2Keys.Data {
			onchainPublicKeys[keyData.Attributes.ChainType] = append(
				onchainPublicKeys[keyData.Attributes.ChainType],
				prefixWith0xIfNeeded(
					// the stringified keys have ocr2on_<chainType>_ as a prefix prior to actually getting
					// the hex public key, so needs to be trimmed first before we can use it everywhere
					// else.
					strings.TrimPrefix(
						keyData.Attributes.OnChainPublicKey,
						fmt.Sprintf("ocr2on_%s_", keyData.Attributes.ChainType),
					),
				),
			)
		}
		Plog.Info().Any("OCR2Keys", ocr2Keys.Data).Msg("Read OCR2 keys from node")
	}

	Plog.Info().Any("OnchainPublicKeys", onchainPublicKeys).Msg("Onchain public keys for all nodes")

	return onchainPublicKeys, nil
}

func launchStandaloneExecutors(in []*services.ExecutorInput) ([]*services.ExecutorOutput, error) {
	var outs []*services.ExecutorOutput
	// Start standalone executors if they are in standalone mode.
	for _, exec := range in {
		if exec != nil && exec.Mode == services.Standalone {
			out, err := services.NewExecutor(exec)
			if err != nil {
				return nil, fmt.Errorf("failed to create executor service: %w", err)
			}
			outs = append(outs, out)
		}
	}
	return outs, nil
}

func launchStandaloneVerifiers(in *Cfg) ([]*services.VerifierOutput, error) {
	var outs []*services.VerifierOutput
	// Start standalone verifiers if in standalone mode.
	for _, ver := range in.Verifier {
		if ver.Mode == services.Standalone {
			out, err := services.NewVerifier(ver)
			if err != nil {
				return nil, fmt.Errorf("failed to create verifier service: %w", err)
			}
			outs = append(outs, out)
		}
	}
	return outs, nil
}

func prefixWith0xIfNeeded(s string) string {
	if strings.HasPrefix(s, "0x") {
		return s
	}
	return "0x" + s
}

// Assignment represents drawing from a list of items without replacement,
// until all items have been drawn. At that point, the assignment will repeat.
// Round robin is an example of such an assignment strategy.
// TODO: probably not the right abstraction but is sufficient for now?
type Assignment[T any] interface {
	// GetNext returns the next item in the assignment.
	GetNext() (index int, item T)
}

// RoundRobinAssignment returns the next item in a round robin fashion.
type RoundRobinAssignment[T any] struct {
	items []T
	index int
}

// NewRoundRobinAssignment creates a new round robin assignment.
func NewRoundRobinAssignment[T any](items []T) Assignment[T] {
	return &RoundRobinAssignment[T]{items: items, index: 0}
}

// GetNext returns the next item in the round robin assignment.
func (a *RoundRobinAssignment[T]) GetNext() (int, T) {
	defer func() { a.index = (a.index + 1) % len(a.items) }()
	return a.index, a.items[a.index]
}

// TODO: this is copied from the toml secret structures in the CL node.
// We can't really import anything from there so this duplication is
// currently necessary.
type Secrets struct {
	CCV CCVSecrets `toml:",omitempty"`
}

func (c *Secrets) TomlString() (string, error) {
	data, err := toml.Marshal(c)
	if err != nil {
		return "", fmt.Errorf("failed to marshal CCV secrets to TOML: %w", err)
	}
	return string(data), nil
}

type CCVSecrets struct {
	AggregatorSecrets []AggregatorSecret `toml:",omitempty"`
	IndexerSecret     *IndexerSecret     `toml:",omitempty"`
}

type AggregatorSecret struct {
	VerifierID string `toml:",omitempty"`
	APIKey     string `toml:",omitempty"`
	APISecret  string `toml:",omitempty"`
}

type IndexerSecret struct {
	APIKey    string `toml:",omitempty"`
	APISecret string `toml:",omitempty"`
}
